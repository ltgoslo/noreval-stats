# Norwegian language models
norolmo-13b:
  display_name: "NorOLMo 13B"
  category: norwegian
  organization: LTG/UiO
  parameters: 13.7
  license: "Apache 2.0"
  description: "Fully-open Norwegian language model continually-trained on OLMo2 (13B stage 2), trained by the Language Technology Group at the University of Oslo."
  huggingface_url: https://huggingface.co/HPLT/NorOLMo-13B
  default: true
  color: "#DD0000"

norolmo-13b-stage1:
  display_name: "NorOLMo 13B (stage 1)"
  category: norwegian
  organization: LTG/UiO
  parameters: 13.7
  license: "Apache 2.0"
  description: "The final stage-1 checkpoint of NorOLMo-13B (after 24,000 steps). NorOLMo is a fully-open Norwegian language model continually-trained on OLMo2, trained by the Language Technology Group at the University of Oslo."
  huggingface_url: https://huggingface.co/HPLT/NorOLMo-13B
  default: false
  color: "#DD0000"

normistral-7b-warm:
  display_name: "NorMistral 7B"
  category: norwegian
  organization: LTG/UiO
  parameters: 7.24
  license: "Apache 2.0"
  description: "Norwegian language model initialized from Mistral-7B-v0.1 and continually-trained on 260 billion subword tokens of Norwegian data. Trained by the Language Technology Group at the University of Oslo."
  huggingface_url: https://huggingface.co/norallm/normistral-7b-warm
  default: true
  color: "#DD0000"

normistral-11b-warm:
  display_name: "NorMistral 11B"
  category: norwegian
  organization: LTG/UiO
  parameters: 11.4
  license: "Apache 2.0"
  description: "Norwegian language model based on Mistral-Nemo-Base-2407, continually-trained on 250 billion tokens of Norwegian, Scandinavian, Sámi and code data. Trained by the Language Technology Group at the University of Oslo."
  huggingface_url: https://huggingface.co/norallm/normistral-11b-warm
  default: true
  color: "#DD0000"

normistral-11b-long:
  display_name: "NorMistral 11B Long"
  category: norwegian
  organization: LTG/UiO
  parameters: 11.4
  license: "Apache 2.0"
  description: "Norwegian language model with extended context length (32k→128k tokens), based on normistral-11b-warm."
  huggingface_url: https://huggingface.co/norallm/normistral-11b-long
  default: true
  color: "#DD0000"

norbert4-xlarge:
  display_name: "NorBERT4 1B"
  category: norwegian
  organization: LTG/UiO
  parameters: 0.987
  license: "Apache 2.0"
  description: "The fourth generation NorBERT model for Norwegian encoding/decoding. Trained from scratch on 600B tokens of Norwegian Bokmål, Nynorsk and Northern Sámi. Trained by the Language Technology Group at the University of Oslo."
  huggingface_url: https://huggingface.co/ltg/norbert4-xlarge
  default: true
  color: "#DD0000"

NorGPT-3B:
  display_name: "NorwAI NorGPT 3B"
  category: norwegian
  organization: NorwAI/NTNU
  parameters: 3.09
  license: "CC BY-NC-SA 4.0"
  description: "Generative pretrained transformer for Norwegian based on GPT-2 architecture. Part of the NorGLM suite trained on ~25B tokens."
  huggingface_url: https://huggingface.co/NorGLM/NorGPT-3B
  default: true
  color: "#00509e"

NorLlama-3B:
  display_name: "NorwAI NorLlama 8B"
  category: norwegian
  organization: NorwAI/NTNU
  parameters: 2.8
  license: "CC BY-NC-SA 4.0"
  description: "Generative pretrained transformer for Norwegian based on LLaMA architecture. Part of the NorGLM suite."
  huggingface_url: https://huggingface.co/NorGLM/NorLlama-3B
  default: true
  color: "#00509e"

NorwAI-Mistral-7B:
  display_name: "NorwAI Mistral 7B"
  category: norwegian
  organization: NorwAI/NTNU
  parameters: 7.53
  license: "NorLLM License"
  description: "Model continually-trained on Mistral-7B-v0.1 using 51B tokens of Norwegian and Nordic data. Part of the NorwAI LLM family from NTNU. Restricted to use within Nordic countries."
  huggingface_url: https://huggingface.co/NorwAI/NorwAI-Mistral-7B
  default: true
  color: "#00509e"

NorwAI-Mixtral-8x7B:
  display_name: "NorwAI Mixtral 8x7B (47B)"
  category: norwegian
  organization: NorwAI/NTNU
  parameters: 47.0
  license: "NorLLM License"
  description: "MoE model continually-trained on Mixtral-8x7B-v0.1 using 51B tokens of Norwegian and Nordic data. Part of the NorwAI LLM family from NTNU. Restricted to use within Nordic countries."
  huggingface_url: https://huggingface.co/NorwAI/NorwAI-Mixtral-8x7B
  default: true
  color: "#00509e"

nb-gpt-j-6B:
  display_name: "NB-GPT-J 6B"
  category: norwegian
  organization: Nasjonalbiblioteket
  parameters: 6.05
  license: "Apache 2.0"
  description: "Norwegian fine-tuned version of GPT-J. Part of the Norwegian National Library's effort to create Norwegian language models."
  huggingface_url: https://huggingface.co/NbAiLab/nb-gpt-j-6B
  default: true
  color: "#40263f"

# Multilingual models
olmo-2-13b (stage 1):
  display_name: "OLMo2 13B (stage 1)"
  category: multilingual
  organization: Allen AI
  parameters: 13.7
  license: "Apache 2.0"
  description: "Specific stage 1 checkpoint of OLMo 2, an open language model trained on 5 trillion tokens by the Allen Institute for AI."
  huggingface_url: https://huggingface.co/allenai/OLMo-2-1124-13B
  default: false
  color: "#f0529c"

OLMo-2-1124-13B:
  display_name: "OLMo2 13B"
  category: multilingual
  organization: Allen AI
  parameters: 13.7
  license: "Apache 2.0"
  description: "Open language model from the Allen Institute for AI trained on 5 trillion tokens."
  huggingface_url: https://huggingface.co/allenai/OLMo-2-1124-13B
  default: true
  color: "#f0529c"

Olmo-3-1025-7B:
  display_name: "OLMo3 7B"
  category: multilingual
  organization: Allen AI
  parameters: 7.3
  license: "Apache 2.0"
  description: "Open language model from the Allen Institute for AI trained on 5.93 trillion tokens with 65k context length."
  huggingface_url: https://huggingface.co/allenai/Olmo-3-1025-7B
  default: true
  color: "#f0529c"

Olmo-3-1125-32B:
  display_name: "OLMo3 32B"
  category: multilingual
  organization: Allen AI
  parameters: 32.25
  license: "Apache 2.0"
  description: "Open language model from the Allen Institute for AI trained on 5.50 trillion tokens with 65k context length."
  huggingface_url: https://huggingface.co/allenai/Olmo-3-1125-32B
  default: true
  color: "#f0529c"

Apertus-8B-2509:
  display_name: "Apertus 8B"
  category: multilingual
  organization: Swiss AI
  parameters: 8.05
  license: "Apache 2.0"
  description: "Multilingual model supporting over 1000 languages, designed for fully-open and transparent language modeling. Trained on 15T tokens."
  huggingface_url: https://huggingface.co/swiss-ai/Apertus-8B-2509
  default: true
  color: "#7ac6dc"

Apertus-70B-2509:
  display_name: "Apertus 70B"
  category: multilingual
  organization: Swiss AI
  parameters: 70.6
  license: "Apache 2.0"
  description: "Multilingual model supporting over 1000 languages, designed for fully-open and transparent language modeling. Trained on 15T tokens."
  huggingface_url: https://huggingface.co/swiss-ai/Apertus-70B-2509
  default: true
  color: "#7ac6dc"

EuroLLM-1.7B:
  display_name: "EuroLLM 1.7B"
  category: multilingual
  organization: EuroLLM
  parameters: 1.66
  license: "Apache 2.0"
  description: "Multilingual transformer supporting European languages."
  huggingface_url: https://huggingface.co/utter-project/EuroLLM-1.7B
  default: true
  color: "#5f9ea0"

EuroLLM-9B-2512:
  display_name: "EuroLLM 9B"
  category: multilingual
  organization: EuroLLM
  parameters: 9.15
  license: "Apache 2.0"
  description: "Multilingual transformer supporting 34 languages, an enhanced version of EuroLLM-9B with long-context extension."
  huggingface_url: https://huggingface.co/utter-project/EuroLLM-9B-2512
  default: true
  color: "#5f9ea0"

EuroLLM-22B-2512:
  display_name: "EuroLLM 22B"
  category: multilingual
  organization: EuroLLM
  parameters: 22.6
  license: "Apache 2.0"
  description: "Multilingual transformer trained on 4 trillion tokens across EU languages. Features Grouped Query Attention and 32k token context window."
  huggingface_url: https://huggingface.co/utter-project/EuroLLM-22B-2512
  default: true
  color: "#5f9ea0"

gemma-3-1b-pt:
  display_name: "Gemma3 1B"
  category: multilingual
  organization: Google
  parameters: 1.0
  license: "Gemma Terms of Use"
  description: "From Google's Gemma 3 family. Supports 140+ languages."
  huggingface_url: https://huggingface.co/google/gemma-3-1b-pt
  default: true
  color: "#3aab58"

gemma-3-4b-pt:
  display_name: "Gemma3 4B"
  category: multilingual
  organization: Google
  parameters: 4.3
  license: "Gemma Terms of Use"
  description: "From Google's Gemma 3 family. Supports 140+ languages."
  huggingface_url: https://huggingface.co/google/gemma-3-4b-pt
  default: true
  color: "#3aab58"

gemma-3-12b-pt:
  display_name: "Gemma3 12B"
  category: multilingual
  organization: Google
  parameters: 12.2
  license: "Gemma Terms of Use"
  description: "Multimodal model from Google trained on 12 trillion tokens. Supports 140+ languages with text and image input."
  huggingface_url: https://huggingface.co/google/gemma-3-12b-pt
  default: true
  color: "#3aab58"

gemma-3-27b-pt:
  display_name: "Gemma3 27B"
  category: multilingual
  organization: Google
  parameters: 27.4
  license: "Gemma Terms of Use"
  description: "Multimodal model from Google trained on 14 trillion tokens. Supports text and image understanding with 128k context window."
  huggingface_url: https://huggingface.co/google/gemma-3-27b-pt
  default: true
  color: "#3aab58"

Llama-3.1-8B:
  display_name: "Llama3.1 8B"
  category: multilingual
  organization: Meta
  parameters: 8.03
  license: "Llama 3.1 Community License"
  description: "Multilingual language model from Meta supporting 8 languages. Trained on 15T+ tokens with 128k context length."
  huggingface_url: https://huggingface.co/meta-llama/Llama-3.1-8B
  default: true
  color: "#0a8af8"

Llama-3.1-70B:
  display_name: "Llama3.1 70B"
  category: multilingual
  organization: Meta
  parameters: 70.6
  license: "Llama 3.1 Community License"
  description: "Multilingual language model from Meta supporting 8 languages. Trained on 15T+ tokens with 128k context length."
  huggingface_url: https://huggingface.co/meta-llama/Llama-3.1-70B
  default: true
  color: "#0a8af8"

Mistral-7B-v0.1:
  display_name: "Mistral 7B"
  category: multilingual
  organization: Mistral AI
  parameters: 7.24
  license: "Apache 2.0"
  description: "Generative text model from Mistral AI that uses Grouped-Query Attention and Sliding-Window Attention."
  huggingface_url: https://huggingface.co/mistralai/Mistral-7B-v0.1
  default: true
  color: "#ff8c00"

Mistral-Nemo-Base-2407:
  display_name: "Mistral Nemo 12B"
  category: multilingual
  organization: Mistral AI
  parameters: 12.2
  license: "Apache 2.0"
  description: "Pretrained generative text model trained jointly by Mistral AI and NVIDIA. Features 128k context window and multilingual support."
  huggingface_url: https://huggingface.co/mistralai/Mistral-Nemo-Base-2407
  default: true
  color: "#ff8c00"

Ministral-3-3B-Base-2512-Llamafied-TextOnly:
  display_name: "Ministral3 3B"
  category: multilingual
  organization: Mistral AI
  parameters: 3.4
  license: "Apache 2.0"
  description: "Text-only language model component of Mistral AI's Ministral 3 (3B) multimodal model, converted to Llama format."
  huggingface_url: https://huggingface.co/mistralai/Ministral-3-3B-Base-2512
  default: true
  color: "#ff8c00"

Ministral-3-8B-Base-2512-Llamafied-TextOnly:
  display_name: "Ministral3 8B"
  category: multilingual
  organization: Mistral AI
  parameters: 8.4
  license: "Apache 2.0"
  description: "Text-only language model component of Mistral AI's Ministral 3 (9B) multimodal model, converted to Llama format."
  huggingface_url: https://huggingface.co/mistralai/Ministral-3-8B-Base-2512
  default: true
  color: "#ff8c00"

Ministral-3-14B-Base-2512-Llamafied-TextOnly:
  display_name: "Ministral3 14B"
  category: multilingual
  organization: Mistral AI
  parameters: 13.5
  license: "Apache 2.0"
  description: "Text-only language model component of Mistral AI's Ministral 3 (14B) multimodal model, converted to Llama format."
  huggingface_url: https://huggingface.co/mistralai/Ministral-3-14B-Base-2512
  default: true
  color: "#ff8c00"

Qwen2.5-32B:
  display_name: "Qwen2.5 32B"
  category: multilingual
  organization: Alibaba
  parameters: 32.5
  license: "Apache 2.0"
  description: "Base language model from Qwen. Multilingual with 29 language support."
  huggingface_url: https://huggingface.co/Qwen/Qwen2.5-32B
  default: true
  color: "#9391fe"

Qwen2.5-72B:
  display_name: "Qwen2.5 72B"
  category: multilingual
  organization: Alibaba
  parameters: 72.7
  license: "Qwen License Agreement"
  description: "Base language model from Qwen. Multilingual with 29 language support."
  huggingface_url: https://huggingface.co/Qwen/Qwen2.5-72B
  default: true
  color: "#9391fe"

Qwen3-1.7B-Base:
  display_name: "Qwen3 1.7B"
  category: multilingual
  organization: Alibaba
  parameters: 1.7
  license: "Apache 2.0"
  description: "Base language model from Qwen. Multilingual with 100+ language support."
  huggingface_url: https://huggingface.co/Qwen/Qwen3-1.7B-Base
  default: true
  color: "#9391fe"

Qwen3-4B-Base:
  display_name: "Qwen3 4B"
  category: multilingual
  organization: Alibaba
  parameters: 4.0
  license: "Apache 2.0"
  description: "Base language model from Qwen. Multilingual with 100+ language support."
  huggingface_url: https://huggingface.co/Qwen/Qwen3-4B-Base
  default: true
  color: "#9391fe"

Qwen3-8B-Base:
  display_name: "Qwen3 8B"
  category: multilingual
  organization: Alibaba
  parameters: 8.2
  license: "Apache 2.0"
  description: "Base language model from Qwen. Multilingual with 100+ language support."
  huggingface_url: https://huggingface.co/Qwen/Qwen3-8B-Base
  default: true
  color: "#9391fe"

Qwen3-14B-Base:
  display_name: "Qwen3 14B"
  category: multilingual
  organization: Alibaba
  parameters: 14.8
  license: "Apache 2.0"
  description: "Base language model from Qwen. Multilingual with 100+ language support."
  huggingface_url: https://huggingface.co/Qwen/Qwen3-14B
  default: true
  color: "#9391fe"

AI-Sweden-Models-Llama-3-8B:
  display_name: "AI Sweden Llama3 8B"
  category: multilingual
  organization: AI Sweden
  parameters: 8.03
  license: "Llama 3 Community License"
  description: "Model based on Llama 3 architecture, continually-trained on Swedish and Nordic data by AI Sweden."
  huggingface_url: https://huggingface.co/AI-Sweden-Models/Llama-3-8B
  default: true
  color: "#fecd08"

gpt-sw3-1.3b:
  display_name: "GPT-SW3 1.3B"
  category: multilingual
  organization: AI Sweden
  parameters: 1.37
  license: "Apache 2.0"
  description: "Autoregressive language model trained on Swedish, Norwegian, Danish, Icelandic, English, and programming code. Developed by AI Sweden and RISE."
  huggingface_url: https://huggingface.co/AI-Sweden-Models/gpt-sw3-1.3b
  default: true
  color: "#fecd08"

gpt-sw3-6.7b-v2:
  display_name: "GPT-SW3 6.7B"
  category: multilingual
  organization: AI Sweden
  parameters: 6.7
  license: "Modified RAIL License"
  description: "Autoregressive language model trained on Swedish, Norwegian, Danish, Icelandic, English, and programming code. Developed by AI Sweden and RISE."
  huggingface_url: https://huggingface.co/AI-Sweden-Models/gpt-sw3-6.7b-v2
  default: true
  color: "#fecd08"

gpt-sw3-20b:
  display_name: "GPT-SW3 20B"
  category: multilingual
  organization: AI Sweden
  parameters: 20.78
  license: "Modified RAIL License"
  description: "Autoregressive language model trained on Swedish, Norwegian, Danish, Icelandic, English, and programming code. Developed by AI Sweden and RISE."
  huggingface_url: https://huggingface.co/AI-Sweden-Models/gpt-sw3-20b
  default: true
  color: "#fecd08"

gpt-sw3-40b:
  display_name: "GPT-SW3 40B"
  category: multilingual
  organization: AI Sweden
  parameters: 40.0
  license: "Modified RAIL License"
  description: "Autoregressive language model trained on Swedish, Norwegian, Danish, Icelandic, English, and programming code. Developed by AI Sweden and RISE."
  huggingface_url: https://huggingface.co/AI-Sweden-Models/gpt-sw3-40b
  default: true
  color: "#fecd08"

Viking-7B:
  display_name: "Viking 7B"
  category: multilingual
  organization: SILO AI
  parameters: 7.55
  license: "Apache 2.0"
  description: "Open language model for Nordic languages developed by SILO AI. Supports Finnish, Swedish, Norwegian, Danish, Icelandic, and English."
  huggingface_url: https://huggingface.co/LumiOpen/Viking-7B
  default: true
  color: "#08aa78"

Viking-13B:
  display_name: "Viking 13B"
  category: multilingual
  organization: SILO AI
  parameters: 14.03
  license: "Apache 2.0"
  description: "Open language model for Nordic languages developed by SILO AI (named 13B after its architecture). Supports Finnish, Swedish, Norwegian, Danish, Icelandic, and English."
  huggingface_url: https://huggingface.co/LumiOpen/Viking-13B
  default: true
  color: "#08aa78"

Viking-33B:
  display_name: "Viking 33B"
  category: multilingual
  organization: SILO AI
  parameters: 33.12
  license: "Apache 2.0"
  description: "Open language model for Nordic languages developed by SILO AI. Supports Finnish, Swedish, Norwegian, Danish, Icelandic, and English."
  huggingface_url: https://huggingface.co/LumiOpen/Viking-33B
  default: true
  color: "#08aa78"

Poro-34B:
  display_name: "Poro 34B"
  category: multilingual
  organization: SILO AI
  parameters: 34.2
  license: "Apache 2.0"
  description: "Open language model for Finnish, English, and code, developed by SILO AI in collaboration with TurkuNLP and the University of Edinburgh."
  huggingface_url: https://huggingface.co/LumiOpen/Poro-34B
  default: true
  color: "#08aa78"

dfm-decoder-open-v0-7b-pt:
  display_name: "DFM 7B"
  category: multilingual
  organization: DFM
  parameters: 7.0
  license: "Apache 2.0"
  description: "Base language model continually pre-trained from Comma v0.1 on 30B tokens of Danish and English data. Developed by Danish Foundation Models with fully open training data, code, and weights."
  huggingface_url: https://huggingface.co/danish-foundation-models/dfm-decoder-open-v0-7b-pt
  default: true
  color: "#c60c30"